{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T04:30:58.409592Z","iopub.status.busy":"2023-10-03T04:30:58.408844Z","iopub.status.idle":"2023-10-03T04:30:58.419476Z","shell.execute_reply":"2023-10-03T04:30:58.418289Z","shell.execute_reply.started":"2023-10-03T04:30:58.409526Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","from sklearn.metrics.pairwise import cosine_similarity\n","from glob import glob\n","import torch\n","from tqdm import tqdm\n","import os\n","import torch\n","import numpy as np\n","from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n","from collections import Counter"]},{"cell_type":"markdown","metadata":{},"source":["## Define some function"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T04:31:07.211691Z","iopub.status.busy":"2023-10-03T04:31:07.211296Z","iopub.status.idle":"2023-10-03T04:31:07.220107Z","shell.execute_reply":"2023-10-03T04:31:07.219226Z","shell.execute_reply.started":"2023-10-03T04:31:07.211656Z"},"trusted":true},"outputs":[],"source":["# Some metrics\n","def cosine_similarity(vector1, vector2):\n","    # Tính cosine similarity sau khi chuẩn hóa vector\n","    return np.dot(vector1 / np.linalg.norm(vector1), vector2 / np.linalg.norm(vector2))\n","\n","def mean_squared_error(vector1, vector2):\n","    # Tính mean squared error\n","    return np.mean((vector1 - vector2) ** 2)\n","\n","def load_model_and_feature_extractor(config):\n","    # Tạo và tải mô hình từ pre-trained checkpoint\n","    model = AutoModelForImageClassification.from_pretrained(config.pretrain_name).to(config.device).eval()\n","\n","    # Tạo feature extractor từ pre-trained checkpoint\n","    feature_extractor = AutoFeatureExtractor.from_pretrained(config.pretrain_name, do_resize=config.do_resize)\n","\n","    return model, feature_extractor\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T04:31:45.121218Z","iopub.status.busy":"2023-10-03T04:31:45.120788Z","iopub.status.idle":"2023-10-03T04:31:45.140956Z","shell.execute_reply":"2023-10-03T04:31:45.139945Z","shell.execute_reply.started":"2023-10-03T04:31:45.121191Z"},"trusted":true},"outputs":[],"source":["class Config:\n","    def __init__(self):\n","        # Định nghĩa các thuộc tính cấu hình\n","        self.pretrain_name = \"/kaggle/input/lab05-pretrained/trained_models/checkpoint-1140\"  # Tên checkpoint pre-trained\n","        self.do_resize = False  # Có thay đổi kích thước ảnh đầu vào hay không\n","        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Thiết bị sử dụng (cuda hoặc cpu)\n","        self.path_train = \"/kaggle/input/lab05-data/dataset/data_new_class/train/\"  # Đường dẫn đến dữ liệu huấn luyện\n","        self.class_new = [i.split('/')[-1] for i in glob(\"/kaggle/input/lab05-data/dataset/data_new_class/test/*\")]  # Danh sách các lớp mới\n","        self.all_folder = glob(\"/kaggle/input/lab05-data/dataset/few_shot_reference/*\")  # Đường dẫn đến thư mục chứa dữ liệu tham chiếu\n","        self.batch_size = 64\n","        self.top_k = 5\n","\n","def wrapper_features_embedding(config, feature_extractor, base_model, batch_img):\n","    # Chuyển batch ảnh thành dạng PyTorch tensor và di chuyển vào GPU (nếu có)\n","    inputs = feature_extractor(images=batch_img, return_tensors=\"pt\").to(config.device)\n","\n","    with torch.no_grad():\n","        # Gọi mô hình và lấy feature embedding\n","        feature_embedding = base_model.beit(**inputs).last_hidden_state\n","\n","        # Chuyển feature embedding thành numpy array\n","        return feature_embedding.view((len(batch_img), -1)).cpu().numpy()\n","\n","\n","def load_reference_embeddings(config, feature_extractor, model):\n","    ref_path = []\n","    ref_classes = []\n","\n","    # Duyệt qua tất cả các thư mục trong thư mục tham chiếu\n","    for folder in config.all_folder:\n","        class_name = folder.split(\"/\")[-1]  # Lấy tên lớp từ tên thư mục\n","        if class_name in config.class_new:  # Kiểm tra xem lớp có trong danh sách lớp mới hay không\n","            # Duyệt qua tất cả các tệp trong thư mục tham chiếu\n","            for file in glob(f\"{folder}/*\"):\n","                ref_classes.append(class_name)  # Thêm tên lớp vào danh sách lớp tham chiếu\n","                ref_path.append(file)  # Thêm đường dẫn tệp vào danh sách đường dẫn tham chiếu\n","\n","    # Tải các hình ảnh tham chiếu vào một danh sách\n","    batch_img = [Image.open(path) for path in ref_path]\n","    # Trích xuất các đặc trưng từ hình ảnh tham chiếu\n","    ref_embeddings = wrapper_features_embedding(config, feature_extractor, model, batch_img)\n","    return ref_embeddings, ref_classes\n","\n","def find_most_common_class(data):\n","    class_counts = Counter(class_name for _, class_name in data)\n","    most_common_class = class_counts.most_common(1)[0][0]\n","\n","    max_count = class_counts[most_common_class]\n","    most_common_classes = [class_name for class_name, count in class_counts.items() if count == max_count]\n","\n","    if len(most_common_classes) > 1:\n","        highest_score = float('-inf')\n","        for class_name in most_common_classes:\n","            score = max(score for score, cn in data if cn == class_name)\n","            if score > highest_score:\n","                highest_score = score\n","                most_common_class = class_name\n","\n","    return most_common_class\n","\n","def predict_class(embedding , ref_embedding, ref_classes, top_k = 5):\n","    list_similarity = [cosine_similarity(embedding, i) for i in ref_embedding]\n","    output = list(zip(list_similarity, ref_classes))\n","    data =  sorted(output, key=lambda x: x[0], reverse = True)[:top_k]\n","    return find_most_common_class(data)\n","\n","\n","def create_image_batches(image_list, batch_size):\n","    image_batches = []  # Danh sách chứa các batch ảnh\n","\n","    for i in range(0, len(image_list), batch_size):\n","        batch = image_list[i:i + batch_size]  # Cắt danh sách ảnh thành batch\n","        image_batches.append(batch)  # Thêm batch vào danh sách các batch\n","\n","    return image_batches\n","\n","\n","def get_data_predict(model, feature_extractor, config):\n","    # Tải embedding và danh sách lớp tham chiếu\n","    ref_embeddings, ref_classes = load_reference_embeddings(config=config, model=model, feature_extractor=feature_extractor)\n","    print(\"Shape reference data: \",ref_embeddings.shape)\n","    inputs = []\n","    # Duyệt qua tất cả các thư mục huấn luyện\n","    for folder in glob(f\"{config.path_train}/*\"):\n","        class_name = folder.split(\"/\")[-1]  # Lấy tên lớp từ tên thư mục\n","        # Duyệt qua tất cả các tệp trong thư mục huấn luyện\n","        for file in glob(f\"{folder}/*\"):\n","            inputs.append((class_name, file))  # Thêm tên lớp và đường dẫn tệp vào danh sách đầu vào\n","\n","    list_pred = []  # Danh sách dự đoán\n","    list_truth = []  # Danh sách thực tế\n","    elements = create_image_batches(inputs, config.batch_size)\n","    for batch_element in tqdm(elements, desc='run'):\n","      batch_image = [Image.open(i[1]) for i in batch_element]  # Mở tệp hình ảnh\n","      batch_label = [i[0] for i in batch_element]\n","      # Trích xuất embedding từ hình ảnh\n","      batch_embedding = wrapper_features_embedding(config, feature_extractor, model, batch_image)\n","      for label, embedding in list(zip(batch_label, batch_embedding)):\n","          pred = predict_class(embedding, ref_embeddings, ref_classes, config.top_k)\n","          list_pred.append(pred)\n","          list_truth.append(label)\n","    return list_pred, list_truth"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T04:31:50.152045Z","iopub.status.busy":"2023-10-03T04:31:50.151603Z","iopub.status.idle":"2023-10-03T04:31:50.210901Z","shell.execute_reply":"2023-10-03T04:31:50.210059Z","shell.execute_reply.started":"2023-10-03T04:31:50.152008Z"},"trusted":true},"outputs":[],"source":["config = Config()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T04:31:53.907246Z","iopub.status.busy":"2023-10-03T04:31:53.906905Z","iopub.status.idle":"2023-10-03T04:32:11.370525Z","shell.execute_reply":"2023-10-03T04:32:11.369608Z","shell.execute_reply.started":"2023-10-03T04:31:53.907222Z"},"trusted":true},"outputs":[],"source":["## Load model and feature extractor\n","model, feature_extractor = load_model_and_feature_extractor(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T04:32:11.372795Z","iopub.status.busy":"2023-10-03T04:32:11.372255Z","iopub.status.idle":"2023-10-03T04:33:59.138136Z","shell.execute_reply":"2023-10-03T04:33:59.137029Z","shell.execute_reply.started":"2023-10-03T04:32:11.372761Z"},"trusted":true},"outputs":[],"source":["list_pred, list_truth = get_data_predict(model, feature_extractor, config)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-03T04:33:59.140944Z","iopub.status.busy":"2023-10-03T04:33:59.140053Z","iopub.status.idle":"2023-10-03T04:34:00.396254Z","shell.execute_reply":"2023-10-03T04:34:00.395354Z","shell.execute_reply.started":"2023-10-03T04:33:59.140907Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","\n","# Tính classification report\n","report = classification_report(list_truth, list_pred, labels=config.class_new)\n","\n","# In classification report\n","print(\"Classification Report:\")\n","print(report)\n","\n","# Tính confusion matrix\n","cm = confusion_matrix(list_truth, list_pred, labels=config.class_new)\n","\n","# Hiển thị confusion matrix dưới dạng biểu đồ\n","plt.figure(figsize=(18,9))\n","plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.title('Confusion Matrix')\n","plt.colorbar()\n","tick_marks = np.arange(len(config.class_new))\n","plt.xticks(tick_marks, config.class_new, rotation=90)\n","plt.yticks(tick_marks, config.class_new)\n","\n","fmt = 'd'\n","thresh = cm.max() / 2.\n","for i in range(cm.shape[0]):\n","    for j in range(cm.shape[1]):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 ha=\"center\", va=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","plt.tight_layout()\n","plt.ylabel('True labels')\n","plt.xlabel('Predicted labels')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
